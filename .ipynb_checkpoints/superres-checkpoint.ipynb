{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "target_size = 32\n",
    "batch_size = 100\n",
    "\n",
    "input = tf.placeholder(tf.float32, [batch_size, input_size, input_size, 1])\n",
    "target = tf.placeholder(tf.float32, [batch_size, target_size**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_w = tf.Variable(tf.random_normal([5, 5, 1, 256], stddev=0.1))\n",
    "conv1_b = tf.Variable(tf.random_normal([256], stddev=0.1))\n",
    "\n",
    "conv2_w = tf.Variable(tf.random_normal([5, 5, 32, 256], stddev=0.1))\n",
    "conv2_b = tf.Variable(tf.random_normal([256], stddev=0.1))\n",
    "\n",
    "weights1 = tf.Variable(tf.random_normal([(input_size//4)*(input_size//4)*256, 5000], stddev=0.1))\n",
    "biases1 = tf.Variable(tf.random_normal([5000], stddev=0.1))\n",
    "\n",
    "weights2 = tf.Variable(tf.random_normal([5000, target_size**2], stddev=0.1))\n",
    "biases2 = tf.Variable(tf.random_normal([target_size**2], stddev=0.1))\n",
    "\n",
    "conv1 = tf.nn.relu(tf.nn.conv2d(input, conv1_w, [1, 1, 1, 1], 'SAME') + conv1_b)\n",
    "pool1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "conv2 = tf.nn.relu(tf.nn.conv2d(pool1, conv2_w, [1, 1, 1, 1], 'SAME') + conv2_b)\n",
    "pool2 = tf.nn.max_pool(conv2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "                      \n",
    "pool2 = tf.reshape(pool2, [batch_size, (input_size//4)*(input_size//4)*256])\n",
    "\n",
    "hidden = tf.nn.softmax(tf.matmul(pool2, weights1) + biases1)\n",
    "output = tf.matmul(hidden, weights2) + biases2\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=output))\n",
    "minimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(target, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 891.6813354492188\n",
      "100: 878.9732666015625\n",
      "200: 892.13330078125\n",
      "300: 846.9141235351562\n",
      "400: 892.6627197265625\n",
      "500: 880.971435546875\n",
      "600: 770.7349243164062\n",
      "700: 945.0413818359375\n",
      "800: 981.9718017578125\n",
      "900: 973.7301635742188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-f3c1a40a452a>\", line 14, in <module>\n",
      "    sess.run(minimizer, feed_dict=feed_dict)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 895, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1124, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1321, in _do_run\n",
      "    options, run_metadata)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1327, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1306, in _run_fn\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/talos/anaconda3/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(10000):\n",
    "    input_batch, labels = mnist.train.next_batch(batch_size)\n",
    "    input_batch = tf.reshape(input_batch, [batch_size, 28, 28, 1])\n",
    "    target_batch = tf.image.resize_images(input_batch, [32, 32], method=1)\n",
    "    input_batch = tf.image.resize_images(input_batch, [16, 16], method=1)\n",
    "    input_batch = np.reshape(input_batch.eval(), input.shape)\n",
    "    target_batch = np.reshape(target_batch.eval(), target.shape)\n",
    "    \n",
    "    feed_dict={input: input_batch, target: target_batch}\n",
    "    \n",
    "    sess.run(minimizer, feed_dict=feed_dict)\n",
    "\n",
    "    if e % 100 is 0:\n",
    "        #train_accuracy = accuracy.eval(feed_dict=feed_dict)\n",
    "        #print(\"Step {}, training batch accuracy {} %\".format(e, train_accuracy*100))\n",
    "        print('{}: {}'.format(e, loss.eval(feed_dict=feed_dict)))\n",
    "        \n",
    "        outimg = tf.reshape(output[0], [32, 32, 1])\n",
    "        outimg = tf.image.convert_image_dtype(outimg, tf.uint8)\n",
    "        outimg = tf.image.encode_png(outimg)\n",
    "        \n",
    "        file = open('/home/talos/xx/x{}.png'.format(e), 'wb+')\n",
    "        file.write(sess.run(outimg, feed_dict=feed_dict))\n",
    "        file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
