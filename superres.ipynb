{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 16\n",
    "target_size = 32\n",
    "batch_size = 100\n",
    "\n",
    "input = tf.placeholder(tf.float32, [batch_size, input_size, input_size, 1])\n",
    "target = tf.placeholder(tf.float32, [batch_size, target_size**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn1 = 1000\n",
    "cn2 = 1000\n",
    "n1 = 5000\n",
    "\n",
    "conv1_w = tf.Variable(tf.random_normal([5, 5, 1, cn1], stddev=0.1))\n",
    "conv1_b = tf.Variable(tf.random_normal([cn1], stddev=0.1))\n",
    "\n",
    "conv2_w = tf.Variable(tf.random_normal([5, 5, cn1, cn2], stddev=0.1))\n",
    "conv2_b = tf.Variable(tf.random_normal([cn2], stddev=0.1))\n",
    "\n",
    "weights1 = tf.Variable(tf.random_normal([(input_size//4)*(input_size//4)*cn2, n1], stddev=0.1))\n",
    "biases1 = tf.Variable(tf.random_normal([n1], stddev=0.1))\n",
    "\n",
    "weights2 = tf.Variable(tf.random_normal([n1, target_size**2], stddev=0.1))\n",
    "biases2 = tf.Variable(tf.random_normal([target_size**2], stddev=0.1))\n",
    "\n",
    "conv1 = tf.nn.relu(tf.nn.conv2d(input, conv1_w, [1, 1, 1, 1], 'SAME') + conv1_b)\n",
    "pool1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "\n",
    "conv2 = tf.nn.relu(tf.nn.conv2d(pool1, conv2_w, [1, 1, 1, 1], 'SAME') + conv2_b)\n",
    "pool2 = tf.nn.max_pool(conv2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "                      \n",
    "pool2 = tf.reshape(pool2, [batch_size, (input_size//4)*(input_size//4)*cn2])\n",
    "\n",
    "hidden = tf.nn.softmax(tf.matmul(pool2, weights1) + biases1)\n",
    "output = tf.matmul(hidden, weights2) + biases2\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=output))\n",
    "minimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(target, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(10000):\n",
    "    input_batch, labels = mnist.train.next_batch(batch_size)\n",
    "    input_batch = tf.reshape(input_batch, [batch_size, 28, 28, 1])\n",
    "    target_batch = tf.image.resize_images(input_batch, [32, 32], method=1)\n",
    "    input_batch = tf.image.resize_images(input_batch, [16, 16], method=1)\n",
    "    input_batch = np.reshape(input_batch.eval(), input.shape)\n",
    "    target_batch = np.reshape(target_batch.eval(), target.shape)\n",
    "    \n",
    "    feed_dict={input: input_batch, target: target_batch}\n",
    "    \n",
    "    sess.run(minimizer, feed_dict=feed_dict)\n",
    "\n",
    "    if e % 100 is 0:\n",
    "        #train_accuracy = accuracy.eval(feed_dict=feed_dict)\n",
    "        #print(\"Step {}, training batch accuracy {} %\".format(e, train_accuracy*100))\n",
    "        print('{}: {}'.format(e, loss.eval(feed_dict=feed_dict)))\n",
    "        \n",
    "        outimg = tf.reshape(output[0], [32, 32, 1])\n",
    "        outimg = tf.image.convert_image_dtype(outimg, tf.uint8)\n",
    "        outimg = tf.image.encode_png(outimg)\n",
    "        \n",
    "        file = open('/home/talos/xx/x{}.png'.format(e), 'wb+')\n",
    "        file.write(sess.run(outimg, feed_dict=feed_dict))\n",
    "        file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
